# -*- coding: utf-8 -*-
"""UI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P1H4Hb_gf4vLILKzeFPW4H4Ad46m1hn3
"""

from datetime import datetime, timedelta, timezone
from PIL import Image, ImageDraw, ImageFont
from matplotlib.dates import DateFormatter
from matplotlib.ticker import MaxNLocator
import matplotlib

matplotlib.use("Agg")  # Needed for rasberry PI
import pytz
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
import requests
import json
import time
import os
import io

initial_tokens = {
    "access_token": "71870655799f709b48db485716c48f4a6172820b",
    "refresh_token": "f998017ecb9a90b957f7a899f577e1f7f8169564",
    "expires_at": 1746223776,
    "expires_in": 21600,
    "token_type": "Bearer",
}

with open("strava_tokens.json", "w") as f:
    json.dump(initial_tokens, f)

# Replace with your client credentials
CLIENT_ID = "157720"
CLIENT_SECRET = "55315723b18529f565a622341257daabed443bd7"
TOKEN_FILE = "strava_tokens.json"


def save_tokens(tokens):
    with open(TOKEN_FILE, "w") as f:
        json.dump(tokens, f)


def load_tokens():
    if os.path.exists(TOKEN_FILE):
        with open(TOKEN_FILE, "r") as f:
            return json.load(f)
    return None


def refresh_access_token(refresh_token):
    print("Refreshing access token...")
    response = requests.post(
        url="https://www.strava.com/oauth/token",
        data={
            "client_id": CLIENT_ID,
            "client_secret": CLIENT_SECRET,
            "grant_type": "refresh_token",
            "refresh_token": refresh_token,
        },
    )
    if response.status_code == 200:
        tokens = response.json()
        save_tokens(tokens)
        return tokens
    else:
        raise Exception("Failed to refresh token: " + response.text)


def get_valid_access_token():
    tokens = load_tokens()
    if tokens is None:
        raise Exception("Token file not found. Run the authorization step first.")

    if time.time() > tokens["expires_at"]:
        tokens = refresh_access_token(tokens["refresh_token"])

    return tokens["access_token"]


def fetch_all_activities(access_token):
    activities = []
    page = 1
    while True:
        response = requests.get(
            "https://www.strava.com/api/v3/athlete/activities",
            headers={"Authorization": f"Bearer {access_token}"},
            params={"per_page": 200, "page": page},
        )
        if response.status_code != 200:
            raise Exception("Failed to fetch activities: " + response.text)
        data = response.json()
        if not data:
            break
        activities.extend(data)
        page += 1
    return activities


def prepare_dataframe(activities):
    df = pd.DataFrame(activities)
    # df = df[df['type'].isin(['Run', 'Walk', 'Hike'])].copy()
    df["start_date"] = pd.to_datetime(df["start_date"])

    # Convert start_date to datetime if needed
    df["start_date"] = pd.to_datetime(df["start_date"])

    # Only convert timezone (no localization)
    df["start_date"] = df["start_date"].dt.tz_convert(central_tz)

    # df['start_date'] = pd.to_datetime(df['start_date']).dt.tz_localize('UTC')
    df["month"] = df["start_date"].dt.to_period("M")

    # Make datetime aware of UTC to match Strava timestamps
    one_year_ago = datetime.now(timezone.utc) - timedelta(days=365)
    df = df[df["start_date"] > one_year_ago]

    df["distance_miles"] = df["distance"] / 1609.34
    return df


file_path = "df.pkl"
hr_file_path = "hr.pkl"
FTHR = 170
central_tz = pytz.timezone("America/Chicago")

try:
    file_age_seconds = time.time() - os.path.getmtime(file_path)
    file_age_seconds_2 = time.time() - os.path.getmtime(hr_file_path)
except:
    file_age_seconds = 999999999

if file_age_seconds < 3600 and file_age_seconds_2 < 3600:
    # File is less than an hour old
    print("Cached data is being used")
    df = pd.read_pickle(file_path)
    hr_df = pd.read_pickle(hr_file_path)
else:
    # File is more than an hour old

    print("New data is being used")
    # Example usage: get a valid token and make an authenticated request
    access_token = get_valid_access_token()
    headers = {"Authorization": f"Bearer {access_token}"}
    response = requests.get("https://www.strava.com/api/v3/athlete", headers=headers)

    if response.ok:
        print("Authenticated athlete data:")
        print(response.json())
    else:
        print("API request failed:", response.text)

    activities = fetch_all_activities(access_token)
    df = prepare_dataframe(activities)
    print("pickling df")
    df.to_pickle(file_path)

    data = []
    for act in activities:
        if act["has_heartrate"] and "average_heartrate" in act:
            date = pd.to_datetime(act["start_date"]).date()
            duration_hours = act["moving_time"] / 3600
            intensity_factor = act["average_heartrate"] / FTHR
            tss = (
                duration_hours * intensity_factor**2 * 100
            )  # TSS formula for HR-based activities
            data.append({"date": date, "TSS": tss})

    hr_df = pd.DataFrame(data)
    print("pickling hr_df")
    hr_df.to_pickle(hr_file_path)

# print("df.shape")
# print(df.shape)
# print("Columns in the DataFrame:")
# for col in df.columns:
#     print(col)

# Ensure elev_high is numeric in case of any bad data
df["elev_high"] = pd.to_numeric(df["elev_high"], errors="coerce")
max_elevation = df["elev_high"].max()

df["duration_hours"] = df["moving_time"] / 3600
df["moving_time"] = pd.to_numeric(df["moving_time"], errors="coerce")
df["average_heartrate"] = pd.to_numeric(df["average_heartrate"], errors="coerce")

# Calculate duration in hours
duration_hours = df["moving_time"] / 3600

# Calculate intensity factor
intensity_factor = df["average_heartrate"] / FTHR

# Calculate TSS using the HR-based formula
df["TSS"] = duration_hours * intensity_factor**2 * 100

# Find the activity with the highest TSS
max_tss_row = df.loc[df["TSS"].idxmax()]

# Print the result
print("Workout with highest TSS:")
print(max_tss_row[["name", "start_date", "TSS", "moving_time", "average_heartrate"]])

# Prepare top 5 TSS per exercise type
top_tss_per_type = (
    df[
        [
            "start_date",
            "type",
            "sport_type",
            "TSS",
            "location_city",
            "location_state",
            "location_country",
            "start_latlng",
            "end_latlng",
            "name",
        ]
    ]
    .dropna(subset=["TSS"])
    .sort_values(["type", "TSS"], ascending=[True, False])
    .groupby("type")
    .head(4)
)

print(top_tss_per_type)
# Loop and print each row in one line with location
print("Top 5 highest TSS workouts per exercise type:\n")
for _, row in top_tss_per_type.iterrows():
    date_str = pd.to_datetime(row["start_date"]).strftime("%Y-%m-%d")

    print(
        f"{date_str} | {row['sport_type']} | TSS: {row['TSS']:.2f} | Name: {row['name']}"
    )

start_date = central_tz.localize(datetime(2025, 5, 17))
today = datetime.now(central_tz)
days_since_start = (today.date() - start_date.date()).days

# === PREPARE SPORT TYPES LIST ===
sport_types = sorted(df["sport_type"].dropna().unique().tolist())
current_index = days_since_start % len(sport_types)
current_sport = sport_types[current_index]

# === FILTER & PRINT ===
subset = (
    df[df["sport_type"] == current_sport].sort_values(by="TSS", ascending=False).head(4)
)

print(f"Top 5 TSS workouts for: {current_sport} (Day {days_since_start})\n")
for _, row in subset.iterrows():
    date_str = pd.to_datetime(row["start_date"]).strftime("%Y-%m-%d")
    print(
        f"{date_str} | {row['sport_type']} | TSS: {row['TSS']:.2f} | Name: {row['name']}"
    )

# Define activity type filters
tennis_types = ["Tennis", "Workout"]
bike_types = ["Ride", "VirtualRide"]

# Filter and sum durations
total_tennis_hours = df[df["type"].isin(tennis_types)]["duration_hours"].sum()
total_bike_hours = df[df["type"].isin(bike_types)]["duration_hours"].sum()

print(f"🎾 Total hours spent playing Tennis: {total_tennis_hours:.2f} hours")
print(f"🚴 Total hours spent Biking (indoor + outdoor): {total_bike_hours:.2f} hours")

# Ensure start_date is in datetime format and timezone-aware
df["start_date"] = pd.to_datetime(df["start_date"]).dt.tz_convert("UTC")

df = df[df["type"].isin(["Run", "Walk", "Hike"])].copy()

# Add distance in miles if not already done
if "distance_miles" not in df.columns:
    df["distance_miles"] = df["distance"] / 1609.34

# Define date ranges
now = datetime.now(timezone.utc)
one_year_ago = now - timedelta(days=365)
two_years_ago = now - timedelta(days=730)

# Total miles by activity type
total_miles = df.groupby("type")["distance_miles"].sum()

# Miles in the last 12 months
last_12_months = df[df["start_date"] > one_year_ago]
miles_last_12 = last_12_months.groupby("type")["distance_miles"].sum()

# Miles from 12–24 months ago
prev_12_months = df[
    (df["start_date"] > two_years_ago) & (df["start_date"] <= one_year_ago)
]
miles_prev_12 = prev_12_months.groupby("type")["distance_miles"].sum()

# Ensure all activity types are included (even those with 0 miles)
activity_types = ["Run", "Walk", "Hike"]
miles_prev_12 = miles_prev_12.reindex(
    activity_types, fill_value=0
)  # Reindex with fill_value=0


# If any value in miles_prev_12 is 0, replace it with the value from miles_last_12
miles_prev_12 = miles_prev_12.where(miles_prev_12 != 0, miles_last_12)

# Print results
print("🏃‍♂️ Total Miles by Activity:")
print(total_miles.round(2), "\n")

print("📅 Miles in Last 12 Months:")
print(miles_last_12.round(2), "\n")

print("📅 Target Miles")
print(miles_prev_12.round(2))

hr_df = (
    hr_df.groupby("date").sum().sort_index()
)  # Sum TSS for multiple activities per day

# 2. Calculate CTL, ATL, and Form
hr_df["CTL"] = hr_df["TSS"].rolling(window=42, min_periods=1).mean()
hr_df["ATL"] = hr_df["TSS"].rolling(window=7, min_periods=1).mean()
hr_df["Form"] = hr_df["CTL"] - hr_df["ATL"]

# 3. Fill any missing dates with 0 TSS
start = hr_df.index.min()

# Ensure we go up to *today in Chicago time*
now_chicago = datetime.now(central_tz).date()
end = max(hr_df.index.max(), now_chicago)

all_days = pd.date_range(start=start, end=end, freq="D")
hr_df = hr_df.reindex(all_days, fill_value=0)
hr_df.index.name = "date"

# Recalculate CTL, ATL, and Form after reindexing
hr_df["CTL"] = hr_df["TSS"].rolling(window=42, min_periods=1).mean()
hr_df["ATL"] = hr_df["TSS"].rolling(window=7, min_periods=1).mean()
hr_df["Form"] = hr_df["CTL"] - hr_df["ATL"]

# 4. Display the final DataFrame
print(hr_df.tail(7).round(2))

# Ensure the date column is a datetime index
hr_df = hr_df.copy()
hr_df.index = pd.to_datetime(hr_df.index)

# Filter the last 30 days
last_month_df = hr_df.loc[hr_df.index >= (hr_df.index.max() - pd.Timedelta(days=90))]

# Set seaborn style
sns.set(style="whitegrid")

max_ctl = last_month_df["CTL"].max()

# Create individual plots
metrics = ["CTL", "ATL", "Form"]
metrics = ["CTL"]
for metric in metrics:
    plt.figure(figsize=(4, 2))
    sns.lineplot(
        data=last_month_df,
        x=last_month_df.index,
        y=metric,
        linewidth=3.5,
        color="black",
    )

# Formatting
plt.xlabel("")
plt.ylabel(metric, fontsize=8)
date_fmt = DateFormatter("%m-%d")
plt.gca().xaxis.set_major_formatter(date_fmt)
plt.gca().xaxis.set_major_locator(MaxNLocator(nbins=5))
plt.xticks(fontsize=6)
plt.gca().yaxis.set_major_locator(MaxNLocator(nbins=4))
plt.yticks(fontsize=8)
plt.gca().grid(True, which="both", axis="both", linestyle="-", linewidth=1.2)
plt.axis("off")
plt.tight_layout(pad=0.5)
# Save to PNG buffer
buf = io.BytesIO()
plt.savefig(buf, format="PNG", dpi=156, facecolor="white")
plt.close()
buf.seek(0)

# Filter last 5 workouts with heart rate data
df = pd.read_pickle(file_path)
hr_filtered = df[df["has_heartrate"] & df["average_heartrate"].notna()]

# Sort by start date descending and take the last 5
last_workouts = hr_filtered.sort_values("start_date", ascending=False).head(5)

print("\nLast 5 workouts:")
for _, act in last_workouts.iterrows():
    dt = pd.to_datetime(act["start_date"]).astimezone(central_tz)
    workout_type = (act["type"] if pd.notna(act["type"]) else "Unknown")[:5]
    duration_hours = act["moving_time"] / 3600
    intensity_factor = act["average_heartrate"] / FTHR
    tss = duration_hours * intensity_factor**2 * 100
    print(f"{dt.strftime('%Y-%m-%d %H:%M')} | {workout_type:<5} | TSS: {tss:.1f}")

# ============================================================================================================================
# I need to do this once I get my display
# Import the correct driver for your model
# from lib import epd2in13_V3  # Update this depending on your exact display
# https://www.waveshare.com/product/raspberry-pi/displays/e-paper/2.15inch-e-paper-hat-plus-g.htm

# # Initialize display
# epd = epd2in13_V3.EPD()
# epd.init(epd.FULL_UPDATE)
# epd.Clear(0xFF)

epd_width = 296
epd_height = 160


font_size = 10
try:
    font_path = "ProFontWindows.ttf"
    font = ImageFont.truetype(font_path, font_size)
    print("Monospaced font found")
except IOError:
    print("Monospaced font not found, falling back to default.")
    font = ImageFont.load_default()

# Create a blank image for drawing (1-bit mode)
image = Image.new(
    "RGB", (epd_width, epd_height), (255, 255, 255)
)  # white background (RGB
draw = ImageDraw.Draw(image)


# Title
y = 0
draw.text((2, y), "    Date   | Type  | TSS ", font=font, fill=0)
y += font_size + 0

# Render the workout summary lines
last_workouts = hr_filtered.sort_values("start_date", ascending=False).head(15)
for _, act in last_workouts.iterrows():
    dt = pd.to_datetime(act["start_date"]).astimezone(central_tz)
    workout_type = (act["type"] if pd.notna(act["type"]) else "Unknown")[:5]
    if workout_type == "Worko":
        workout_type = "Tennis"
    elif workout_type == "Weigh":
        workout_type = "Lift "
    duration_hours = act["moving_time"] / 3600
    intensity_factor = act["average_heartrate"] / FTHR
    tss = duration_hours * intensity_factor**2 * 100
    # Rendering
    line = f"{dt.strftime('%m-%d %H:%M')}|{workout_type:<7}|{tss:.1f}"
    draw.text((2, y), line, font=font, fill=0)
    y += font_size + 0  # add spacing between lines

# Load image and draw diagonal stripes
plot_img = Image.open(buf).convert("L")  # grayscale first
draw = ImageDraw.Draw(plot_img)

# Get image dimensions
width, height = plot_img.size

y_max = last_month_df[metric].max()
y_min = last_month_df[metric].min()


def ctl_to_pixel(ctl_value):
    """Convert CTL value to pixel y-coordinate (top = 0)."""
    ctl_value = round(ctl_value)
    return int(height * (1 - (ctl_value - y_min) / (y_max - y_min)))


# y_top = min(ctl_to_pixel(80), ctl_to_pixel(max_ctl))
y_top = ctl_to_pixel(max(80, max_ctl))
# y_top = ctl_to_pixel(80)
print(f"y_top{(80, max_ctl)}")
y_bottom = ctl_to_pixel(60)
print(f"{(y_top, y_bottom)}")


# Loop over the rectangular area between y_top and y_bottom
# Define checker square size
# Square size and spacing
square_size = 2
gap = 1  # space between squares

step = square_size + gap  # total step per square unit

# Draw checkerboard pattern with gaps
for y in range(y_top, y_bottom, step):
    for x in range(0, width, step):
        # Offset every other row for checker pattern
        if (x // step + y // step) % 2 == 0:
            draw.rectangle(
                [x, y, x + square_size - 1, y + square_size - 1],
                fill=0,  # black square
            )

# Convert to 1-bit and paste onto display
plot_img = plot_img.convert("1")  # final 1-bit conversion for e-ink

# Resize and paste as before
quarter_width = epd_width // 2
quarter_height = epd_height // 2
plot_img = plot_img.resize((quarter_width, quarter_height))
image.paste(plot_img, (0, epd_height - quarter_height))


# CTL ATL FIT
# Draw three black boxes in the top-right corner
# Draw one black box in the top-right corner
font_size = 20
try:
    font_path = "ProFontWindows.ttf"
    font = ImageFont.truetype(font_path, font_size)
    print("Monospaced font found")
except IOError:
    print("Monospaced font not found, falling back to default.")
    font = ImageFont.load_default()

draw = ImageDraw.Draw(image)
box_width = 48
box_height = 25
box_spacing = 2

labels = ["CTL", "ATL", "FIT"]  # Text for each box

start_x = epd_width - (3 * box_width + 2 * box_spacing)
start_y = 0  # top of the image

for i, label in enumerate(labels):
    x0 = start_x + i * (box_width + box_spacing)
    y0 = start_y
    x1 = x0 + box_width
    y1 = y0 + box_height

    # Check if label is 'atl' to change the colors
    if label.lower() == "atl":  # Case insensitive comparison
        box_fill = "red"  # Red box
        text_fill = "yellow"  # Yellow text
    else:
        box_fill = 0  # Black box for other labels
        text_fill = 255  # White text for other labels

    # Draw black rectangle
    draw.rectangle([x0, y0, x1, y1], fill=box_fill)

    # Center the text
    bbox = font.getbbox(label)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]
    text_x = x0 + (box_width - text_width) // 2
    text_y = y0 + (box_height - text_height) // 2

    # Draw white text
    draw.text((text_x, text_y), label, font=font, fill=text_fill)

# value boxes
start_y = 27  # top of the image
values = hr_df.iloc[-1].round().tolist()
values_prev = hr_df.iloc[-8].round().tolist()
for i, label in enumerate(labels):
    x0 = start_x + i * (box_width + box_spacing)
    y0 = start_y
    x1 = x0 + box_width
    y1 = y0 + box_height

    # Check if label is 'atl' to change the colors
    if label.lower() != "atl":  # Case insensitive comparison
        box_fill = "red"  # Red box
        text_fill = "yellow"  # Yellow text
    else:
        box_fill = 0  # Black box for other labels
        text_fill = 255  # White text for other labels

    # Draw black rectangle
    draw.rectangle([x0, y0, x1, y1], fill=box_fill)

    # Center the text
    text = str(int(values[i + 1]))
    if values[i + 1] > values_prev[i + 1]:
        text = "^" + text
    else:
        text = "v" + text
    bbox = font.getbbox(text)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]
    text_x = x0 + (box_width - text_width) // 2
    text_y = y0 + (box_height - text_height) // 2

    # Draw white text
    draw.text((text_x, text_y), str(text), font=font, fill=text_fill)

# cumulative activities
font_size = 10
try:
    font_path = "ProFontWindows.ttf"
    font = ImageFont.truetype(font_path, font_size)
    print("Monospaced font found")
except IOError:
    print("Monospaced font not found, falling back to default.")
    font = ImageFont.load_default()

y = 54

# Render the workout summary lines
for activity_type, total_distance in total_miles.items():
    print(f"Activity: {activity_type}, Total Miles: {total_distance}")

    # Rendering
    line = f"{activity_type} Total Miles: {round(total_distance, 1)}"
    draw.text((epd_width // 2 + 2, y), line, font=font, fill=0)
    y += font_size + 0  # add spacing between lines

print(f"🎾 Total hours spent playing Tennis: {total_tennis_hours:.2f} hours")
line = f"Tennis hours: {round(total_tennis_hours, 1)}"
draw.text((epd_width // 2 + 2, y), line, font=font, fill=0)
y += font_size + 0
print(f"Highest elevation reached in a workout: {int(round(max_elevation))} meters")
line = f"Elevation PR: {int(round(max_elevation))} meters"
draw.text((epd_width // 2 + 2, y), line, font=font, fill=0)
y += font_size + 0

line = f"Top 4 workouts for: {current_sport}"
draw.text((epd_width // 2 + 2, y), line, font=font, fill=0)
y += font_size + 0
for _, row in subset.iterrows():
    date_str = pd.to_datetime(row["start_date"]).strftime("%Y-%m-%d")
    print(
        f"{date_str} | {row['sport_type']} | TSS: {row['TSS']:.2f} | Name: {row['name']}"
    )

    # Rendering
    if pd.isna(row["TSS"]):
        row["TSS"] = 0
    line = f"{date_str[2:]}|{int(round(row['TSS']))}|{row['name'][0:14]}"
    draw.text((epd_width // 2 + 2, y), line, font=font, fill=0)
    y += font_size + 0  # add spacing between lines

image.save("test_output.png")
image.show()

# # Display image on e-ink
# epd.display(epd.getbuffer(image))
# epd.sleep()


# analysis
# Check the memory usage
total_memory = df.memory_usage(deep=True).sum()

# Convert bytes to MB
total_memory_MB = total_memory / (1024 * 1024)
print(f"Total memory usage: {total_memory_MB:.2f} MB")

total_memory = hr_df.memory_usage(deep=True).sum()

# Convert bytes to MB
total_memory_MB = total_memory / (1024 * 1024)
print(f"Total memory usage: {total_memory_MB:.2f} MB")
